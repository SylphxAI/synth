# Incremental Markdown Parser - å®ç°è·¯çº¿å›¾

## ğŸ¯ ç›®æ ‡

ä»é›¶å®ç°ä¸–ç•Œæœ€å¿«çš„å¢é‡ Markdown Parserï¼Œå®Œå…¨å–ä»£ unified/remarkã€‚

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- ğŸš€ 50-100x è§£æé€Ÿåº¦
- âš¡ 10-100x å¢é‡è§£æé€Ÿåº¦
- ğŸ’ª 120x Transform é€Ÿåº¦
- ğŸ”¥ 1000x Query é€Ÿåº¦
- ğŸ’¾ 70% å†…å­˜é‡ç”¨ç‡

---

## ğŸ“‹ å®ç°é˜¶æ®µ

### **Phase 1: æ¶æ„è®¾è®¡**ï¼ˆDay 1ï¼‰

#### 1.1 å®šä¹‰ Token ç±»å‹
- [ ] Block tokens (heading, paragraph, code, list, etc.)
- [ ] Inline tokens (text, emphasis, strong, link, code, etc.)
- [ ] Position tracking (line, column, offset)
- [ ] Token metadata (depth, ordered, checked, etc.)

#### 1.2 è®¾è®¡ Tokenizer æ¥å£
- [ ] `tokenize(text: string): Token[]` - å…¨é‡ tokenize
- [ ] `retokenize(text, edit, oldTokens): Token[]` - å¢é‡ tokenize
- [ ] Token èŒƒå›´æŸ¥æ‰¾ç®—æ³•
- [ ] Token é‡ç”¨ç­–ç•¥

#### 1.3 è®¾è®¡ Parser æ¥å£
- [ ] `parse(text: string): Tree` - å…¨é‡è§£æ
- [ ] `parseIncremental(text, edit): Tree` - å¢é‡è§£æ
- [ ] èŠ‚ç‚¹æ„å»ºç­–ç•¥
- [ ] ç»“æ„å…±äº«æœºåˆ¶

---

### **Phase 2: Tokenizer å®ç°**ï¼ˆDay 1-2ï¼‰

#### 2.1 åŸºç¡€æ¡†æ¶
```typescript
class IncrementalTokenizer {
  private tokens: Token[] = []
  private source: string = ''

  // æ ¸å¿ƒæ–¹æ³•
  tokenize(text: string): Token[]
  retokenize(text: string, edit: Edit, oldTokens: Token[]): Token[]

  // è¾…åŠ©æ–¹æ³•
  private scanLine(line: string, lineStart: number): Token[]
  private findAffectedTokenRange(edit: Edit): { start: number, end: number }
  private reuseUnaffectedTokens(oldTokens: Token[], range: Range): Token[]
}
```

#### 2.2 Block Token è¯†åˆ«
- [ ] Heading (`#`, `##`, etc.)
- [ ] Code block (` ``` `)
- [ ] List (`-`, `*`, `1.`)
- [ ] Blockquote (`>`)
- [ ] Horizontal rule (`---`, `***`)
- [ ] Paragraph (default)

#### 2.3 Inline Token è¯†åˆ«
- [ ] Text (default)
- [ ] Emphasis (`*text*`, `_text_`)
- [ ] Strong (`**text**`, `__text__`)
- [ ] Code (`` `code` ``)
- [ ] Link (`[text](url)`)
- [ ] Image (`![alt](url)`)

#### 2.4 å¢é‡ Tokenization
```typescript
retokenize(text: string, edit: Edit, oldTokens: Token[]): Token[] {
  // 1. æ‰¾åˆ°å—å½±å“çš„ token èŒƒå›´
  const { start, end } = this.findAffectedTokenRange(edit)

  // 2. æå–å—å½±å“çš„æ–‡æœ¬
  const affectedText = text.slice(
    oldTokens[start].position.start.offset,
    edit.newEndByte
  )

  // 3. Re-tokenize å—å½±å“çš„éƒ¨åˆ†
  const newTokens = this.scanText(affectedText, startOffset)

  // 4. åˆå¹¶ï¼šé‡ç”¨ + æ–° tokens + é‡ç”¨
  return [
    ...oldTokens.slice(0, start),
    ...newTokens,
    ...oldTokens.slice(end + 1)
  ]
}
```

---

### **Phase 3: Parser å®ç°**ï¼ˆDay 2-3ï¼‰

#### 3.1 åŸºç¡€æ¡†æ¶
```typescript
class IncrementalMarkdownParser {
  private tokenizer = new IncrementalTokenizer()
  private tree: Tree | null = null
  private tokens: Token[] = []

  // æ ¸å¿ƒæ–¹æ³•
  parse(text: string): Tree
  parseIncremental(text: string, edit: Edit): Tree

  // è¾…åŠ©æ–¹æ³•
  private buildTree(tokens: Token[]): Tree
  private buildNode(token: Token, parent: NodeId): NodeId
  private reparseAffectedNodes(tokens: Token[], range: Range): NodeId[]
  private mergeNodes(oldTree: Tree, newNodes: NodeId[], range: Range): Tree
}
```

#### 3.2 AST æ„å»º
```typescript
buildTree(tokens: Token[]): Tree {
  const tree = createTree('markdown', this.source)

  for (const token of tokens) {
    const nodeId = this.buildNode(token, tree.root)
    tree.nodes[tree.root].children.push(nodeId)
  }

  return tree
}

buildNode(token: Token, parent: NodeId): NodeId {
  // æ ¹æ® token ç±»å‹åˆ›å»ºå¯¹åº”çš„èŠ‚ç‚¹
  // å¤„ç†åµŒå¥—ç»“æ„ï¼ˆå¦‚ list items, blockquotesï¼‰
  // é€’å½’å¤„ç† inline tokens
}
```

#### 3.3 å¢é‡è§£æ
```typescript
parseIncremental(text: string, edit: Edit): Tree {
  // 1. å¢é‡ tokenize
  this.tokens = this.tokenizer.retokenize(text, edit, this.tokens)

  // 2. æ‰¾åˆ°å—å½±å“çš„èŠ‚ç‚¹èŒƒå›´
  const affectedRange = this.findAffectedNodes(edit)

  // 3. Re-parse å—å½±å“çš„èŠ‚ç‚¹
  const newNodes = this.reparseAffectedNodes(this.tokens, affectedRange)

  // 4. ç»“æ„å…±äº«ï¼ˆé‡ç”¨æœªæ”¹å˜çš„èŠ‚ç‚¹ï¼‰
  this.tree = this.mergeNodes(this.tree, newNodes, affectedRange)

  // 5. é‡Šæ”¾æ—§èŠ‚ç‚¹åˆ° pool
  this.releaseAffectedNodes(affectedRange)

  return this.tree
}
```

---

### **Phase 4: CommonMark è¯­æ³•æ”¯æŒ**ï¼ˆDay 3-5ï¼‰

#### ä¼˜å…ˆçº§é¡ºåºï¼ˆä»ç®€åˆ°éš¾ï¼‰

**Day 3: åŸºç¡€å—çº§å…ƒç´ **
- [x] Headings (ATX style: `# Heading`)
- [x] Paragraphs
- [x] Line breaks (soft and hard)
- [x] Thematic breaks (`---`)

**Day 4: å†…è”å…ƒç´ **
- [x] Text
- [x] Emphasis (`*italic*`)
- [x] Strong (`**bold**`)
- [x] Code (`` `code` ``)
- [x] Links (`[text](url)`)
- [x] Images (`![alt](url)`)

**Day 5: é«˜çº§å—çº§å…ƒç´ **
- [x] Code blocks (` ```lang `)
- [x] Lists (ordered and unordered)
- [x] Nested lists
- [x] Blockquotes
- [x] Nested blockquotes

---

### **Phase 5: æµ‹è¯•å’ŒéªŒè¯**ï¼ˆDay 5-6ï¼‰

#### 5.1 å•å…ƒæµ‹è¯•
- [ ] Tokenizer æµ‹è¯•ï¼ˆæ¯ç§ token ç±»å‹ï¼‰
- [ ] Parser æµ‹è¯•ï¼ˆæ¯ç§è¯­æ³•ï¼‰
- [ ] å¢é‡ tokenization æµ‹è¯•
- [ ] å¢é‡è§£ææµ‹è¯•
- [ ] è¾¹ç•Œæƒ…å†µæµ‹è¯•

#### 5.2 é›†æˆæµ‹è¯•
```typescript
describe('Incremental Markdown Parser', () => {
  it('should parse basic markdown', () => {
    const parser = new IncrementalMarkdownParser()
    const tree = parser.parse('# Hello\n\nWorld')
    // éªŒè¯ AST ç»“æ„
  })

  it('should handle incremental edits', () => {
    const parser = new IncrementalMarkdownParser()
    parser.parse('# Hello\n\nWorld')

    // æ¨¡æ‹Ÿç¼–è¾‘
    const tree = parser.parseIncremental('# Hello World\n\nWorld', {
      start: 7,
      oldLength: 0,
      newLength: 6
    })

    // éªŒè¯èŠ‚ç‚¹é‡ç”¨
    expect(stats.reusedNodes).toBeGreaterThan(0)
  })
})
```

#### 5.3 æ€§èƒ½åŸºå‡†æµ‹è¯•
```typescript
describe('Performance Benchmarks', () => {
  // vs Mock parserï¼ˆè¯æ˜çœŸå® parser çš„ä»·å€¼ï¼‰
  bench('Full parse - Mock parser', () => { /* ... */ })
  bench('Full parse - Real parser', () => { /* ... */ })

  // å¢é‡è§£ææ€§èƒ½
  bench('Incremental parse (1% edit)', () => { /* ... */ })
  bench('Incremental parse (10% edit)', () => { /* ... */ })

  // çœŸå®åœºæ™¯
  bench('Typing simulation (100 chars)', () => { /* ... */ })
  bench('Live preview (edit + re-render)', () => { /* ... */ })
})
```

---

### **Phase 6: GFM æ‰©å±•**ï¼ˆDay 7-10ï¼‰

#### 6.1 Tables
```markdown
| Header 1 | Header 2 |
|----------|----------|
| Cell 1   | Cell 2   |
```

#### 6.2 Task Lists
```markdown
- [x] Completed task
- [ ] Incomplete task
```

#### 6.3 Strikethrough
```markdown
~~strikethrough text~~
```

#### 6.4 Autolinks
```markdown
https://example.com
```

---

### **Phase 7: å…¶ä»–æ‰©å±•**ï¼ˆDay 11-14ï¼‰

#### 7.1 Frontmatter
```yaml
---
title: My Post
date: 2024-01-01
---
```

#### 7.2 Math
```latex
$inline math$

$$
block math
$$
```

#### 7.3 Footnotes
```markdown
Here's a sentence with a footnote[^1].

[^1]: This is the footnote.
```

---

## ğŸ¯ æ€§èƒ½ç›®æ ‡

### **è§£ææ€§èƒ½**
- Full parse: **50-100x faster** than remark
- Incremental parse (1% edit): **10-100x faster** than full re-parse
- Incremental parse (10% edit): **5-10x faster** than full re-parse

### **å†…å­˜æ•ˆç‡**
- Node reuse rate: **70%+**
- Memory allocations: **-70%** vs full re-parse
- GC pressure: **minimal**

### **çœŸå®åœºæ™¯**
- Typing (1 char): **<1ms** (vs 10ms full re-parse)
- Live preview (1000 lines): **<10ms** (vs 100ms full re-parse)
- Large file (10000 lines): **<100ms** (vs 1000ms full re-parse)

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### **åŠŸèƒ½å®Œæ•´æ€§**
- [x] æ”¯æŒ CommonMark æ ¸å¿ƒè¯­æ³•
- [ ] æ”¯æŒ GFM æ‰©å±•
- [ ] æ”¯æŒå¸¸è§æ‰©å±•ï¼ˆfrontmatter, mathï¼‰
- [ ] é€šè¿‡ CommonMark spec æµ‹è¯•å¥—ä»¶

### **æ€§èƒ½æ ‡å‡†**
- [ ] è§£æé€Ÿåº¦ > 50x remark
- [ ] å¢é‡è§£æé€Ÿåº¦ > 10x full re-parse
- [ ] å†…å­˜é‡ç”¨ç‡ > 70%
- [ ] æ‰€æœ‰æ“ä½œ < 100ms (10000 è¡Œæ–‡æ¡£)

### **è´¨é‡æ ‡å‡†**
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ— å·²çŸ¥ bug
- [ ] å®Œæ•´ API æ–‡æ¡£

---

## ğŸš€ ä¸‹ä¸€æ­¥

**ç«‹å³å¼€å§‹ Phase 1.1**: å®šä¹‰ Token ç±»å‹å’Œæ¥å£

å‡†å¤‡å¥½äº†ï¼è®©æˆ‘ä»¬å¼€å§‹é€ ä¸–ç•Œæœ€å¿«çš„ Markdown Parserï¼ğŸ’ª
